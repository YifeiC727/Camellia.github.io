[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This is my website! I am a junior student @ Mount Holyoke College, majoring in statistics and politics.\nHi! My name is Yifei Chen, and I am a junior at Mount Holyoke College. I am interested in machine learning and statistics. Love you!\n\n\n\nMy Profile Picture\n\n\nTo contact me, please reach out via LinkedIn.\n123"
  },
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "STAT 244-SC",
    "section": "",
    "text": "This project investigates the factors that influence the total insurance claim amount using a dataset of over 600 real-world auto insurance claims. We explore how both quantitative variables—such as age, property damage value, and months as a customer—and categorical variables—such as education level, incident type, and incident severity—are related to the claim amount. Our goal is to identify meaningful patterns and potential predictors of high insurance claims, using exploratory data analysis and visualization techniques. This analysis may provide insights into claim behavior that could support better risk assessment and fraud detection strategies.\n\n\n\n\n\n\n\nfraud &lt;- read.csv(\"insurance_claims.csv\")\n\nhead(fraud)\n\n  months_as_customer age policy_number policy_bind_date policy_state policy_csl\n1                328  48        521585       2014-10-17           OH    250/500\n2                228  42        342868       2006-06-27           IN    250/500\n3                134  29        687698       2000-09-06           OH    100/300\n4                256  41        227811       1990-05-25           IL    250/500\n5                228  44        367455       2014-06-06           IL   500/1000\n6                256  39        104594       2006-10-12           OH    250/500\n  policy_deductable policy_annual_premium umbrella_limit insured_zip\n1              1000               1406.91              0      466132\n2              2000               1197.22        5000000      468176\n3              2000               1413.14        5000000      430632\n4              2000               1415.74        6000000      608117\n5              1000               1583.91        6000000      610706\n6              1000               1351.10              0      478456\n  insured_sex insured_education_level insured_occupation insured_hobbies\n1        MALE                      MD       craft-repair        sleeping\n2        MALE                      MD  machine-op-inspct         reading\n3      FEMALE                     PhD              sales     board-games\n4      FEMALE                     PhD       armed-forces     board-games\n5        MALE               Associate              sales     board-games\n6      FEMALE                     PhD       tech-support  bungie-jumping\n  insured_relationship capital.gains capital.loss incident_date\n1              husband         53300            0    2015-01-25\n2       other-relative             0            0    2015-01-21\n3            own-child         35100            0    2015-02-22\n4            unmarried         48900       -62400    2015-01-10\n5            unmarried         66000       -46000    2015-02-17\n6            unmarried             0            0    2015-01-02\n             incident_type  collision_type incident_severity\n1 Single Vehicle Collision  Side Collision      Major Damage\n2            Vehicle Theft               ?      Minor Damage\n3  Multi-vehicle Collision  Rear Collision      Minor Damage\n4 Single Vehicle Collision Front Collision      Major Damage\n5            Vehicle Theft               ?      Minor Damage\n6  Multi-vehicle Collision  Rear Collision      Major Damage\n  authorities_contacted incident_state incident_city  incident_location\n1                Police             SC      Columbus     9935 4th Drive\n2                Police             VA     Riverwood       6608 MLK Hwy\n3                Police             NY      Columbus  7121 Francis Lane\n4                Police             OH     Arlington   6956 Maple Drive\n5                  None             NY     Arlington       3041 3rd Ave\n6                  Fire             SC     Arlington 8973 Washington St\n  incident_hour_of_the_day number_of_vehicles_involved property_damage\n1                        5                           1             YES\n2                        8                           1               ?\n3                        7                           3              NO\n4                        5                           1               ?\n5                       20                           1              NO\n6                       19                           3              NO\n  bodily_injuries witnesses police_report_available total_claim_amount\n1               1         2                     YES              71610\n2               0         0                       ?               5070\n3               2         3                      NO              34650\n4               1         2                      NO              63400\n5               0         1                      NO               6500\n6               0         2                      NO              64100\n  injury_claim property_claim vehicle_claim auto_make auto_model auto_year\n1         6510          13020         52080      Saab        92x      2004\n2          780            780          3510  Mercedes       E400      2007\n3         7700           3850         23100     Dodge        RAM      2007\n4         6340           6340         50720 Chevrolet      Tahoe      2014\n5         1300            650          4550    Accura        RSX      2009\n6         6410           6410         51280      Saab         95      2003\n  fraud_reported X_c39\n1              Y    NA\n2              Y    NA\n3              N    NA\n4              Y    NA\n5              N    NA\n6              Y    NA"
  },
  {
    "objectID": "test.html#introduction",
    "href": "test.html#introduction",
    "title": "STAT 244-SC",
    "section": "",
    "text": "This project investigates the factors that influence the total insurance claim amount using a dataset of over 600 real-world auto insurance claims. We explore how both quantitative variables—such as age, property damage value, and months as a customer—and categorical variables—such as education level, incident type, and incident severity—are related to the claim amount. Our goal is to identify meaningful patterns and potential predictors of high insurance claims, using exploratory data analysis and visualization techniques. This analysis may provide insights into claim behavior that could support better risk assessment and fraud detection strategies.\n\n\n\n\n\n\n\nfraud &lt;- read.csv(\"insurance_claims.csv\")\n\nhead(fraud)\n\n  months_as_customer age policy_number policy_bind_date policy_state policy_csl\n1                328  48        521585       2014-10-17           OH    250/500\n2                228  42        342868       2006-06-27           IN    250/500\n3                134  29        687698       2000-09-06           OH    100/300\n4                256  41        227811       1990-05-25           IL    250/500\n5                228  44        367455       2014-06-06           IL   500/1000\n6                256  39        104594       2006-10-12           OH    250/500\n  policy_deductable policy_annual_premium umbrella_limit insured_zip\n1              1000               1406.91              0      466132\n2              2000               1197.22        5000000      468176\n3              2000               1413.14        5000000      430632\n4              2000               1415.74        6000000      608117\n5              1000               1583.91        6000000      610706\n6              1000               1351.10              0      478456\n  insured_sex insured_education_level insured_occupation insured_hobbies\n1        MALE                      MD       craft-repair        sleeping\n2        MALE                      MD  machine-op-inspct         reading\n3      FEMALE                     PhD              sales     board-games\n4      FEMALE                     PhD       armed-forces     board-games\n5        MALE               Associate              sales     board-games\n6      FEMALE                     PhD       tech-support  bungie-jumping\n  insured_relationship capital.gains capital.loss incident_date\n1              husband         53300            0    2015-01-25\n2       other-relative             0            0    2015-01-21\n3            own-child         35100            0    2015-02-22\n4            unmarried         48900       -62400    2015-01-10\n5            unmarried         66000       -46000    2015-02-17\n6            unmarried             0            0    2015-01-02\n             incident_type  collision_type incident_severity\n1 Single Vehicle Collision  Side Collision      Major Damage\n2            Vehicle Theft               ?      Minor Damage\n3  Multi-vehicle Collision  Rear Collision      Minor Damage\n4 Single Vehicle Collision Front Collision      Major Damage\n5            Vehicle Theft               ?      Minor Damage\n6  Multi-vehicle Collision  Rear Collision      Major Damage\n  authorities_contacted incident_state incident_city  incident_location\n1                Police             SC      Columbus     9935 4th Drive\n2                Police             VA     Riverwood       6608 MLK Hwy\n3                Police             NY      Columbus  7121 Francis Lane\n4                Police             OH     Arlington   6956 Maple Drive\n5                  None             NY     Arlington       3041 3rd Ave\n6                  Fire             SC     Arlington 8973 Washington St\n  incident_hour_of_the_day number_of_vehicles_involved property_damage\n1                        5                           1             YES\n2                        8                           1               ?\n3                        7                           3              NO\n4                        5                           1               ?\n5                       20                           1              NO\n6                       19                           3              NO\n  bodily_injuries witnesses police_report_available total_claim_amount\n1               1         2                     YES              71610\n2               0         0                       ?               5070\n3               2         3                      NO              34650\n4               1         2                      NO              63400\n5               0         1                      NO               6500\n6               0         2                      NO              64100\n  injury_claim property_claim vehicle_claim auto_make auto_model auto_year\n1         6510          13020         52080      Saab        92x      2004\n2          780            780          3510  Mercedes       E400      2007\n3         7700           3850         23100     Dodge        RAM      2007\n4         6340           6340         50720 Chevrolet      Tahoe      2014\n5         1300            650          4550    Accura        RSX      2009\n6         6410           6410         51280      Saab         95      2003\n  fraud_reported X_c39\n1              Y    NA\n2              Y    NA\n3              N    NA\n4              Y    NA\n5              N    NA\n6              Y    NA"
  },
  {
    "objectID": "test.html#data-visualization",
    "href": "test.html#data-visualization",
    "title": "STAT 244-SC",
    "section": "Data Visualization",
    "text": "Data Visualization\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\nfraud &lt;- read.csv(\"insurance_claims.csv\")\nhead(fraud)\n\n  months_as_customer age policy_number policy_bind_date policy_state policy_csl\n1                328  48        521585       2014-10-17           OH    250/500\n2                228  42        342868       2006-06-27           IN    250/500\n3                134  29        687698       2000-09-06           OH    100/300\n4                256  41        227811       1990-05-25           IL    250/500\n5                228  44        367455       2014-06-06           IL   500/1000\n6                256  39        104594       2006-10-12           OH    250/500\n  policy_deductable policy_annual_premium umbrella_limit insured_zip\n1              1000               1406.91              0      466132\n2              2000               1197.22        5000000      468176\n3              2000               1413.14        5000000      430632\n4              2000               1415.74        6000000      608117\n5              1000               1583.91        6000000      610706\n6              1000               1351.10              0      478456\n  insured_sex insured_education_level insured_occupation insured_hobbies\n1        MALE                      MD       craft-repair        sleeping\n2        MALE                      MD  machine-op-inspct         reading\n3      FEMALE                     PhD              sales     board-games\n4      FEMALE                     PhD       armed-forces     board-games\n5        MALE               Associate              sales     board-games\n6      FEMALE                     PhD       tech-support  bungie-jumping\n  insured_relationship capital.gains capital.loss incident_date\n1              husband         53300            0    2015-01-25\n2       other-relative             0            0    2015-01-21\n3            own-child         35100            0    2015-02-22\n4            unmarried         48900       -62400    2015-01-10\n5            unmarried         66000       -46000    2015-02-17\n6            unmarried             0            0    2015-01-02\n             incident_type  collision_type incident_severity\n1 Single Vehicle Collision  Side Collision      Major Damage\n2            Vehicle Theft               ?      Minor Damage\n3  Multi-vehicle Collision  Rear Collision      Minor Damage\n4 Single Vehicle Collision Front Collision      Major Damage\n5            Vehicle Theft               ?      Minor Damage\n6  Multi-vehicle Collision  Rear Collision      Major Damage\n  authorities_contacted incident_state incident_city  incident_location\n1                Police             SC      Columbus     9935 4th Drive\n2                Police             VA     Riverwood       6608 MLK Hwy\n3                Police             NY      Columbus  7121 Francis Lane\n4                Police             OH     Arlington   6956 Maple Drive\n5                  None             NY     Arlington       3041 3rd Ave\n6                  Fire             SC     Arlington 8973 Washington St\n  incident_hour_of_the_day number_of_vehicles_involved property_damage\n1                        5                           1             YES\n2                        8                           1               ?\n3                        7                           3              NO\n4                        5                           1               ?\n5                       20                           1              NO\n6                       19                           3              NO\n  bodily_injuries witnesses police_report_available total_claim_amount\n1               1         2                     YES              71610\n2               0         0                       ?               5070\n3               2         3                      NO              34650\n4               1         2                      NO              63400\n5               0         1                      NO               6500\n6               0         2                      NO              64100\n  injury_claim property_claim vehicle_claim auto_make auto_model auto_year\n1         6510          13020         52080      Saab        92x      2004\n2          780            780          3510  Mercedes       E400      2007\n3         7700           3850         23100     Dodge        RAM      2007\n4         6340           6340         50720 Chevrolet      Tahoe      2014\n5         1300            650          4550    Accura        RSX      2009\n6         6410           6410         51280      Saab         95      2003\n  fraud_reported X_c39\n1              Y    NA\n2              Y    NA\n3              N    NA\n4              Y    NA\n5              N    NA\n6              Y    NA\n\n\n\nfraud_new &lt;- select(fraud, months_as_customer, age, number_of_vehicles_involved, bodily_injuries, injury_claim, property_claim, insured_sex, property_damage, insured_education_level, incident_type, incident_severity, total_claim_amount, fraud_reported)\n\nfraud_new &lt;- fraud_new %&gt;% rename(edu_level = insured_education_level, vehicles_involved = number_of_vehicles_involved)\n\n\nfraud_new &lt;- fraud_new %&gt;% \n  mutate_if(is.character, as.factor)\n\n\nfraud_new &lt;- fraud_new %&gt;%\n  mutate(edu_level = as.character(edu_level)) %&gt;%\n  mutate(edu_level = case_when(\n    edu_level %in% c(\"Masters\", \"JD\", \"MD\", \"PhD\") ~ \"Advanced Degree\",\n    TRUE ~ edu_level\n  )) %&gt;%\n  mutate(edu_level = as.factor(edu_level))\n\n\nfraud_new_missing &lt;- fraud_new %&gt;% \n  filter(property_damage == \"?\")\n\nfraud_new_missing %&gt;% count(edu_level)\n\n        edu_level   n\n1 Advanced Degree 208\n2       Associate  55\n3         College  40\n4     High School  57\n\nfraud_new_missing %&gt;% count(fraud_new_missing$insured_sex)\n\n  fraud_new_missing$insured_sex   n\n1                        FEMALE 199\n2                          MALE 161\n\nfraud_new_missing %&gt;% count(incident_type)\n\n             incident_type   n\n1  Multi-vehicle Collision 152\n2               Parked Car  31\n3 Single Vehicle Collision 145\n4            Vehicle Theft  32\n\nfraud_new_missing %&gt;% count(incident_severity)\n\n  incident_severity   n\n1      Major Damage 115\n2      Minor Damage 110\n3        Total Loss  97\n4    Trivial Damage  38\n\n\n\nfraud_new &lt;- fraud_new %&gt;%\n  filter(!apply(fraud_new, 1, function(row) any(grepl(\"\\\\?\", row))))\n\n\nfraud_new &lt;- fraud_new %&gt;% \n  mutate_if(is.character, as.factor)\n\n\nggplot(fraud_new, aes(x = total_claim_amount, fill = edu_level)) + \n  geom_density(alpha = 0.4) + \n  labs(title = \"Density Plot of Total Claim Amount by Education Level\",\n       x = \"Total Claim Amount\",\n       y = \"Density\") + \n  theme_minimal() + \n  theme(legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10))\n\n\n\n\n\n\n\n\n123"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to my homepage!",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "K-Means-Mini-Demo-2.html",
    "href": "K-Means-Mini-Demo-2.html",
    "title": "Lab: K-Means",
    "section": "",
    "text": "Getting Started\n\n\n\n\n\n\nDownload the .qmd file from Moodle and any needed .xlsx or .csv data files. Save these in the same folder/directory.\nOpen the Quarto file in RStudio: File &gt; Open File... &gt;. If you’re working on the MHC RStudio server, you need to upload the files first: go to the Files panel, then click Upload. Upload the .qmd file and any data files. You will need to upload each file one at a time.\nUpdate the author and date in the YAML header of this file.\nClick the Render button. If successful, you should have a new window pop up with a nice looking HTML document.\nFor this lab, you may need to still the package glmnet.\n\nAsk for help if you encounter issues on any of the steps above. Once you’ve successfully made it through these steps, you can continue.\n\n\n\n\nLoad Packages\nYou likely will need to install some these packages before you can run the code chunk below successfully.\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(factoextra)\nlibrary(amap)\n\n\n\nLoad Penguin Data\n\ndata(penguins)\n\n\n\nData Cleaning\n\n# Remove missing values\npenguins &lt;- penguins %&gt;%\n            filter(!is.na(bill_length_mm) & !is.na(bill_depth_mm) & !is.na(species))\n\n# Make data table (named penguins_reduced) that only has\n# bill_length_mm and bill_depth_mm columns\npenguins_reduced &lt;- penguins %&gt;% select(bill_length_mm, bill_depth_mm)\n\n\n\nInitial Visualization\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) + \n  geom_point() \n\n\n\n\n\n\n\n\nWe’ll cluster these penguins based on their bill lengths and depths:\n\n\nImplement \\(K\\)-Means\nComplete the code below to run the K-means algorithm using K = 3.\n\nset.seed(244)\n# Run the K-means algorithm\nkmeans_3_round_1 &lt;- kmeans(scale(penguins_reduced), centers = 3) \n    \n# Plot the cluster assignments\npenguins_reduced %&gt;% \n  mutate(kmeans_cluster = as.factor(kmeans_3_round_1$cluster)) %&gt;%\n  ggplot(aes(x = bill_length_mm, y = bill_depth_mm, color = kmeans_cluster)) + \n  geom_point(size = 3) + \n  theme(legend.position = \"none\") + \n  labs(title = \"K-means with K = 3 (round 1)\") + \n  theme_minimal()\n\n\n\n\n\n\n\n\n\nWhy do we have to set the seed for K-means? In practice, why should we try out a variety of seeds?\n\nAnswer. For reproducibility. Every time we run the function `kmeans`, it initializes the centers of the clusters to be in random locations. It’s possible that some random locations give better clustering results than others; since k-means is a greedy algorithm, it is possible for it to have different results each time, and it’s possible for it to get stuck at a local solution.\n\n\nK-Means Clusters Versus Known Species Groupings\n\n  ggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species)) + \n  geom_point(size = 3) + \n  theme(legend.position = \"none\") + \n  labs(title = \"Actual Groupings of Data Based on Species\") + \n  theme_minimal()\n\n\n\n\n\n\n\n\n\nVisually, how well do you think \\(K\\)-means captured the underlying species structure of the data?\n\nAnswer. It found roughly the data points corresponding to each of the species groups, so it is identifying that as a way to structure the data\n\n\nTuning \\(K\\)\n\nTo implement K-means clustering we must choose an appropriate K! Use the following example to see the two different extreme situations. Typically, the ideal \\(K\\) is somewhere between the two extremes.\nMinimum: \\(K = 2\\) groups/clusters\nMaximum: \\(K = n\\) groups/clusters (one observation per cluster)\n\nWhat happens in the \\(K\\)-means algorithm if \\(K = n\\)?\nAnswer. YOUR ANSWER HERE\nLet’s consider anywhere from \\(K = 2\\) to \\(K = 20\\) clusters.\n\nset.seed(244)\n\nk_2  &lt;- kmeans(scale(penguins_reduced), centers = 2)\nk_20 &lt;- kmeans(scale(penguins_reduced), centers = 20)\n\npenguins_reduced %&gt;% \n  mutate(cluster_2 = as.factor(k_2$cluster)) %&gt;% \n  ggplot(aes(x = bill_length_mm, y = bill_depth_mm, color = cluster_2)) + \n    geom_point(size = 3) + \n    labs(title = \"K = 2\")\n\n\n\n\n\n\n\npenguins_reduced %&gt;% \n  mutate(cluster_20 = as.factor(k_20$cluster)) %&gt;% \n  ggplot(aes(x = bill_length_mm, y = bill_depth_mm, color = cluster_20)) + \n    geom_point(size = 3) + \n    labs(title = \"K = 20\") + \n    scale_color_manual(values = rainbow(20))\n\n\n\n\n\n\n\n\nWhat are your general impressions?\nAnswer. YOUR ANSWER HERE\n\n\nFinding Ideal K Value: Silhoutte\n\nThe average silhouette approach measures the quality of a clustering. That is, it determines how well each object lies within its cluster.\n\nTo do so, it maximizes the distance between clusters and minimizes distance within clusters.\n\nA high average silhouette indicates a good clustering.\nGiven a range of possible K values, the optimal number of clusters (K) is the one that maximizes the average silhouette.\n\nWe can use a built-in silhouette method in the fviz_nbclust function to compute the average silhouette for various K values.\n\nfviz_nbclust(scale(penguins_reduced), kmeans, method='silhouette')\n\n\n\n\n\n\n\n\nBased on the average silhouette approach, what is the optimal \\(K\\) value?\nAnswer. The optimal value for k appears to be k = 3\n\n\nExperimenting with Distance Metrics\nWe can use the Kmeans method (notice the “K” is capitalized in this function name) from the amap library to specify how we are measuring distance in the K-means algorithm.\n\nset.seed(244)\nk_2_manattan = Kmeans(scale(penguins_reduced), centers = 3, \n                      method = \"manhattan\")\nk_2_euclid = Kmeans(scale(penguins_reduced), centers = 3, \n                    method = \"euclidean\")\nk_2_maxnorm = Kmeans(scale(penguins_reduced), centers = 3, \n                     method = \"maximum\")\n\n\n\nfviz_cluster(k_2_euclid, data = scale(penguins_reduced), \n             main = sprintf(\"K = %d Clusters w/ Manhattan Distance\", 3))\n\n\n\n\n\n\n\nfviz_cluster(k_2_manattan, data = scale(penguins_reduced),\n             main = sprintf(\"K = %d Clusters w/ Manhattan Distance\", 3))\n\n\n\n\n\n\n\nfviz_cluster(k_2_maxnorm, data = scale(penguins_reduced),\n             main = sprintf(\"K = %d Clusters w/ Manhattan Distance\", 3))\n\n\n\n\n\n\n\n\nTry changing \\(K\\) to equal 3$ in the code chunk above. How do the clusterings using the 3 distance metrics compare? What do you generally observe?\nAnswer. YOUR ANSWER HERE\nModify the code in the chunk above so that we can easily change the value of K (rather than making sure to change K manually in every line). In general coding practices, is called extracting out a constant."
  },
  {
    "objectID": "test.html#part-2-data-cleaning",
    "href": "test.html#part-2-data-cleaning",
    "title": "STAT 244-SC",
    "section": "Part 2: Data Cleaning",
    "text": "Part 2: Data Cleaning\n\n6. Do the variables have names that are easy to use in code?\n\nfraud_new &lt;- select(fraud, months_as_customer, age, number_of_vehicles_involved, bodily_injuries, injury_claim, property_claim, insured_sex, property_damage, insured_education_level, incident_type, incident_severity, total_claim_amount, fraud_reported)\n\nfraud_new &lt;- fraud_new %&gt;% rename(edu_level = insured_education_level, vehicles_involved = number_of_vehicles_involved)\n\n\n\n7. Do your quantitative variables have the correct types\n\nsapply(fraud_new, class)\n\nmonths_as_customer                age  vehicles_involved    bodily_injuries \n         \"integer\"          \"integer\"          \"integer\"          \"integer\" \n      injury_claim     property_claim        insured_sex    property_damage \n         \"integer\"          \"integer\"        \"character\"        \"character\" \n         edu_level      incident_type  incident_severity total_claim_amount \n       \"character\"        \"character\"        \"character\"          \"integer\" \n    fraud_reported \n       \"character\" \n\n\n\n\n8. Do your categorical variables have the type factor?\n\nfraud_new &lt;- fraud_new %&gt;% \n  mutate_if(is.character, as.factor)\n\n\nsapply(fraud_new, class)\n\n\n\n9. Are there any variables you need to create?\n\nfraud_new &lt;- fraud_new %&gt;%\n  mutate(edu_level = case_when(\n    edu_level %in% c(\"Masters\", \"JD\", \"MD\", \"PhD\") ~ \"Advanced Degree\",\n    TRUE ~ edu_level\n  ))\n\n\n\n10. are their any missing values?\n\nfraud_new_missing &lt;- fraud_new %&gt;% \n  filter(property_damage == \"?\")\n\nfraud_new_missing %&gt;% count(edu_level)\n\n        edu_level   n\n1 Advanced Degree 208\n2       Associate  55\n3         College  40\n4     High School  57\n\nfraud_new_missing %&gt;% count(fraud_new_missing$insured_sex)\n\n  fraud_new_missing$insured_sex   n\n1                        FEMALE 199\n2                          MALE 161\n\nfraud_new_missing %&gt;% count(incident_type)\n\n             incident_type   n\n1  Multi-vehicle Collision 152\n2               Parked Car  31\n3 Single Vehicle Collision 145\n4            Vehicle Theft  32\n\nfraud_new_missing %&gt;% count(incident_severity)\n\n  incident_severity   n\n1      Major Damage 115\n2      Minor Damage 110\n3        Total Loss  97\n4    Trivial Damage  38\n\n\n\nfraud_new &lt;- fraud_new %&gt;%\n  filter(!apply(fraud_new, 1, function(row) any(grepl(\"\\\\?\", row))))\n\n\n\n11. How many observational units (rows) do you have after the previous step?\n\nnrow(fraud_new)\n\n[1] 640\n\nfraud_new &lt;- fraud_new %&gt;% \n  mutate_if(is.character, as.factor)"
  },
  {
    "objectID": "test.html#part3-exploratory-data-analysis",
    "href": "test.html#part3-exploratory-data-analysis",
    "title": "STAT 244-SC",
    "section": "Part3: Exploratory Data Analysis",
    "text": "Part3: Exploratory Data Analysis\n\n1. Provide any numerical summaries that are relevant to your research question.\n\nprint(summary(fraud_new$total_claim_amount))\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    100   41925   58500   53137   70848  114920 \n\n\n\nclass(fraud_new$months_as_customer)\n\n[1] \"integer\"\n\nsummary(fraud_new$months_as_customer)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    1.0   115.0   203.0   204.5   277.2   479.0 \n\n\n\ncount(fraud_new, edu_level)\n\n        edu_level   n\n1 Advanced Degree 365\n2       Associate  90\n3         College  82\n4     High School 103\n\n\n\n#ggpairs(fraud_new)\n\n\n\n2. Provide any visualizations that are relevant to your research question\n\nVisualizaiton of the outcome variable\n\n# total_claim visualization\np1 &lt;- ggplot(fraud_new, aes(x = total_claim_amount)) +\n  geom_histogram(fill = \"lightgreen\", bins = 30, color = \"white\") +\n  ggtitle(\"Histogram of total_claim_amount\") +\n  xlab(\"Amount of the Claims\")\n\np2 &lt;- ggplot(fraud_new, aes(x = property_claim)) +\n  geom_histogram(fill = \"skyblue\", bins = 30, color = \"white\") +\n  ggtitle(\"Histogram of property_claim\") +\n  xlab(\"Amount of the Claim\")\n\np3 &lt;- ggplot(fraud_new, aes(x = injury_claim)) +\n  geom_histogram(fill = \"red\", bins = 30, color = \"white\") +\n  ggtitle(\"Histogram of injury_claim\") +\n  xlab(\"Amount of the Claim\")\n\ngrid.arrange(p1, p2, p3, ncol = 3)\n\n\n\n\n\n\n\n\n\n\nVisualizaiton of a quantitative predictor\n\nproperty_claim_hist &lt;- hist(fraud_new$property_claim,\n     main = \"Histogram of property_claim\",\n     xlab = \"amount of the claim\",\n     col = \"skyblue\",\n     breaks = 30,\n     border = \"white\")\n\n\n\n\n\n\n\n\n\n\nVisualization of a categorical predictor\n\nggplot(data = fraud_new, aes(x = edu_level)) + \n  geom_bar(position = \"dodge\") + \n  labs(\n    title = \"Count for different education level\",\n    x = \"Education group\",\n    y = \"Count\",\n    fill = \"Subscribed\"\n  ) + \n  theme_minimal()+\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\nOverlaid density plot for different education\n\nggplot(fraud_new, aes(x = total_claim_amount, fill = edu_level)) + \n  geom_density(alpha = 0.9) + \n  labs(title = \"Density Plot of Total Claim Amount by Education Level\",\n       x = \"Total Claim Amount\",\n       y = \"Density\") + \n  theme_minimal() + \n  theme(legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10))\n\n\n\n\n\n\n\n\n\n\nK-means Clustering of Total Claim Amount (k = 3)\n\n#set.seed(123)\n\n#claim_kmeans &lt;- kmeans(fraud_new$total_claim_amount, centers = 3)\n\n#fraud_new$claim_cluster &lt;- as.factor(claim_kmeans$cluster)\n\n#ggplot(fraud_new, aes(x = total_claim_amount, fill = claim_cluster)) + \n#  geom_histogram(bins = 30, alpha = 0.6, position = \"identity\") +\n#  labs(title = \"K-means Clustering of Total Claim Amount (k = 3)\",\n#       x = \"Total Claim Amount\",\n#       y = \"Count\") +\n#  theme_minimal()\n\n\n\nRelationship betweeen property claim and total_claim_amount\n\nggplot(data = fraud_new, mapping = aes(x = age, y = total_claim_amount, color = fraud_reported)) +\n  geom_point()+\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\nAdded Variable Plot\n\nlibrary(car)\n\nmod &lt;- lm(total_claim_amount ~ bodily_injuries + vehicles_involved + months_as_customer + property_damage + incident_type + incident_severity, data = fraud_new)\n\navPlots(mod, ask = FALSE)"
  },
  {
    "objectID": "test.html#subset-selection-combine-the-cross-validation-and-backward-seleciton",
    "href": "test.html#subset-selection-combine-the-cross-validation-and-backward-seleciton",
    "title": "STAT 244-SC",
    "section": "Subset Selection: Combine the Cross Validation and Backward Seleciton",
    "text": "Subset Selection: Combine the Cross Validation and Backward Seleciton\n\nlibrary(caret)\nlibrary(stringr)\nlibrary(leaps)\n\nCheck if there’s collinearity\n\nX &lt;- model.matrix(total_claim_amount ~ ., data = fraud_new)\ncaret::findLinearCombos(X)\n\n$linearCombos\n$linearCombos[[1]]\n[1] 10  1  9\n\n\n$remove\n[1] 10\n\ncolnames(model.matrix(total_claim_amount ~ ., data = fraud_new))\n\n [1] \"(Intercept)\"                          \n [2] \"months_as_customer\"                   \n [3] \"age\"                                  \n [4] \"vehicles_involved\"                    \n [5] \"bodily_injuries\"                      \n [6] \"injury_claim\"                         \n [7] \"property_claim\"                       \n [8] \"insured_sexMALE\"                      \n [9] \"property_damageNO\"                    \n[10] \"property_damageYES\"                   \n[11] \"edu_levelAssociate\"                   \n[12] \"edu_levelCollege\"                     \n[13] \"edu_levelHigh School\"                 \n[14] \"incident_typeParked Car\"              \n[15] \"incident_typeSingle Vehicle Collision\"\n[16] \"incident_typeVehicle Theft\"           \n[17] \"incident_severityMinor Damage\"        \n[18] \"incident_severityTotal Loss\"          \n[19] \"incident_severityTrivial Damage\"      \n[20] \"fraud_reportedY\"                      \n\n\n\nlibrary(forcats)\n\nfraud_new &lt;- fraud_new %&gt;%\n  mutate(property_damage = as.character(property_damage)) %&gt;%  # transfer into characteres\n  mutate(property_damage = na_if(property_damage, \"?\")) %&gt;%    # delete \"?\"\n  mutate(property_damage = as.factor(property_damage)) %&gt;%     # transfer back to factors\n  mutate(property_damage = fct_drop(property_damage))       # remove the factor that haven't been used\n\nlevels(fraud_new$property_damage)\n\n[1] \"NO\"  \"YES\"\n\n\n\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))\nfraud_new$property_damage &lt;- C(fraud_new$property_damage, contr = \"contr.sum\")\nstr(fraud_new$property_damage)\n\n Factor w/ 2 levels \"NO\",\"YES\": 2 1 1 1 1 1 2 2 2 1 ...\n - attr(*, \"contrasts\")= chr \"contr.sum\"\n\nX &lt;- model.matrix(total_claim_amount ~ ., data = fraud_new)\ncaret::findLinearCombos(X)  # Return to a empty list\n\n$linearCombos\nlist()\n\n$remove\nNULL\n\n\n\nIdentify at least p = 3 predictors for modeling the expected response E(Y) of one of your variables Y.\nThe variables we selected are: months_as_customer, age, vehicles_involved, bodily_injuries, injury_claim, property_claim, insured_sex1, property_damage1, edu_level1, edu_level2, edu_level3, incident_type1, incident_type2, incident_type3, incident_severity1, incident_severity2, incident_severity3, fraud_reported1, claim_cluster1, claim_cluster2\n\n\nImplement backward subset selection\n\nset.seed(123)\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))\nregfit.bwd &lt;- regsubsets(total_claim_amount ~ ., data = fraud_new, nvmax = 18, method = \"backward\")\n\nsummary(regfit.bwd)\n\n\n\nBackward Selection\n\nset.seed(123)\n\nnum_folds_cv &lt;- 10\ncross_folds_inds_cv &lt;- caret::createFolds(y = fraud_new$total_claim_amount, k = num_folds_cv)\n\nresult_mse_cv &lt;- expand.grid(\n  models = 1:18,\n  fold_num = 1:num_folds_cv,\n  train_mse = NA,\n  test_mse = NA\n)\ncv_errors &lt;- data.frame(model = 1:18, cverr = NA)\n\n# 3. Cross-validation loop\nfor (i in 1:18) {\n  for (fold_num in 1:num_folds_cv) {\n    test_idx &lt;- cross_folds_inds_cv[[fold_num]]\n    fraud_train &lt;- fraud_new[-test_idx, ]\n    fraud_test  &lt;- fraud_new[test_idx, ]\n    \n    # Construct model matrices (dummy vars handled automatically)\n    X_train &lt;- model.matrix(total_claim_amount ~ ., data = fraud_train)\n    y_train &lt;- fraud_train$total_claim_amount\n    X_test  &lt;- model.matrix(total_claim_amount ~ ., data = fraud_test)\n    y_test  &lt;- fraud_test$total_claim_amount\n\n    coefs &lt;- coef(regfit.bwd, i)\n    selected_vars &lt;- names(coefs)[names(coefs) != \"(Intercept)\"]\n    \n    available_vars &lt;- colnames(X_train)\n    valid_vars &lt;- selected_vars[selected_vars %in% available_vars]\n    \n    if (length(valid_vars) == 0) {\n      warning(sprintf(\"Model %d: No valid variables found\", i))\n      next  # Skip the current iteration\n    }\n    \n    # Subset predictors and convert to data frame\n    X_train_sub &lt;- as.data.frame(X_train[, selected_vars, drop = FALSE])\n    X_test_sub  &lt;- as.data.frame(X_test[, selected_vars, drop = FALSE])\n    \n    # Add response variable to training data\n    train_data &lt;- cbind(y_train = y_train, X_train_sub)\n    \n    # Fit linear model\n    red_cv &lt;- lm(y_train ~ ., data = train_data)\n    \n    # Predict - ensure newdata has same column names as training data\n    pred_train &lt;- predict(red_cv, newdata = X_train_sub)\n    pred_test  &lt;- predict(red_cv, newdata = X_test_sub)\n    \n    # Store MSEs\n    result_mse_cv$train_mse[result_mse_cv$models == i & result_mse_cv$fold_num == fold_num] &lt;- mean((y_train - pred_train)^2)\n    result_mse_cv$test_mse[result_mse_cv$models == i & result_mse_cv$fold_num == fold_num] &lt;- mean((y_test - pred_test)^2)\n  }\n  \n  # Average test error for each model size\n  cv_errors$cverr[i] &lt;- mean(result_mse_cv$test_mse[result_mse_cv$models == i])\n}\n\n# 4. Find the best model\ng &lt;- which.min(cv_errors$cverr)\nbest_vars &lt;- names(coef(regfit.bwd, g))\nbest_vars &lt;- best_vars[best_vars != \"(Intercept)\"]\n\ncat(\"The best model contains\", g, \"variables:\\n\")\n\nThe best model contains 7 variables:\n\nprint(best_vars)\n\n[1] \"injury_claim\"    \"property_claim\"  \"edu_level3\"      \"incident_type1\" \n[5] \"incident_type2\"  \"incident_type3\"  \"fraud_reported1\"\n\nbest_coefs &lt;- coef(regfit.bwd, g)\ncat(\"Coefficients of the best model:\\n\")\n\nCoefficients of the best model:\n\nprint(best_coefs)\n\n    (Intercept)    injury_claim  property_claim      edu_level3  incident_type1 \n    15420.07559         2.08911         1.97732      -926.17207     11497.30861 \n incident_type2  incident_type3 fraud_reported1 \n   -12287.44067     12978.43432     -1142.09969 \n\ncat(\"\\nMean Test MSE of the best model:\\n\")\n\n\nMean Test MSE of the best model:\n\nprint(cv_errors$cverr[g])\n\n[1] 67466469\n\nplot(cv_errors$model, cv_errors$cverr, type = \"b\", pch = 16, col = \"blue\",\n     xlab = \"Number of Predictors\", ylab = \"CV MSE\",\n     main = \"Cross-Validation Error by Model Size\")\nabline(v = g, col = \"red\", lty = 2)\n\n\n\n\n\n\n\n\n\ndecode_selected_vars &lt;- sapply(selected_vars, function(var) {\n  if (grepl(\"1|2|3$\", var)) {  # Match the variable name\n    base_var &lt;- sub(\"\\\\d+$\", \"\", var)  # extract the original variable name without the number\n    contrast_num &lt;- as.numeric(sub(\".*(\\\\d+)$\", \"\\\\1\", var))  # extract the number\n    levels &lt;- levels(fraud_new[[base_var]])\n    paste0(base_var, \" (Contrast: \", levels[contrast_num], \" vs others)\")\n  } else {\n    var  # keep the continous variables\n  }\n})\nprint(decode_selected_vars)\n\n                                            months_as_customer \n                                          \"months_as_customer\" \n                                                           age \n                                                         \"age\" \n                                             vehicles_involved \n                                           \"vehicles_involved\" \n                                               bodily_injuries \n                                             \"bodily_injuries\" \n                                                  injury_claim \n                                                \"injury_claim\" \n                                                property_claim \n                                              \"property_claim\" \n                                                  insured_sex1 \n                    \"insured_sex (Contrast: FEMALE vs others)\" \n                                              property_damage1 \n                    \"property_damage (Contrast: NO vs others)\" \n                                                    edu_level1 \n             \"edu_level (Contrast: Advanced Degree vs others)\" \n                                                    edu_level2 \n                   \"edu_level (Contrast: Associate vs others)\" \n                                                    edu_level3 \n                     \"edu_level (Contrast: College vs others)\" \n                                                incident_type1 \n \"incident_type (Contrast: Multi-vehicle Collision vs others)\" \n                                                incident_type2 \n              \"incident_type (Contrast: Parked Car vs others)\" \n                                                incident_type3 \n\"incident_type (Contrast: Single Vehicle Collision vs others)\" \n                                            incident_severity1 \n        \"incident_severity (Contrast: Major Damage vs others)\" \n                                            incident_severity2 \n        \"incident_severity (Contrast: Minor Damage vs others)\" \n                                            incident_severity3 \n          \"incident_severity (Contrast: Total Loss vs others)\" \n                                               fraud_reported1 \n                      \"fraud_reported (Contrast: N vs others)\""
  },
  {
    "objectID": "test.html#cross-validation-with-2-models",
    "href": "test.html#cross-validation-with-2-models",
    "title": "STAT 244-SC",
    "section": "Cross Validation with 2 models",
    "text": "Cross Validation with 2 models\n\nWrite a brief introduction to cross validation which includes relevant mathematical notation.\nCross Validation (CV) is used for the purpose of (1) selection of tuning parameters, (2) variable selections, and (3) assessing the quality of model fit to avoid issues like overfitting.\nIn \\(k\\)-fold cross-validation, the dataset is randomly partitioned into \\(k\\) disjoint subsets (folds) of roughly equal size. For each fold \\(j = 1, 2, \\dots, k\\), the model is trained on the data excluding the \\(j\\)-th fold, and the prediction error is computed on the held-out fold. The estimated MSE is predicted by:\n\\[\\begin{equation}\n\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} \\left( y_i - \\hat{f}(x_i) \\right)^2\n\\end{equation}\\]\nThen, the CV is:\n\\[\n\\text{CV} = \\frac{1}{k} \\sum_{i=1}^{k} \\text{MSE}_i\n\\]\nwhere \\(k\\) is the number of folds you select. For each model, CV helps with estimating and calculating \\(MSE_{\\text{test}}\\). By using CV, we aim to choose models that balance underfitting and overfitting to improve predictive accuracy.\n\n\nWhat linear models are you considering based on your research question? Pick at least two models to compare.\nWe gathered the linear models based on the backward variable selection results, so there are a total of () model candidates. Here is the list of candidates models we are comparing using CV:\nmodel A: total_claim_amount ~ age + vehicles_involved + injury_claim model B (full model): total_claim_amount ~ months_as_customer + age + vehicles_involved + bodily_injuries + injury_claim + property_claim + insured_sex + property_damage + edu_level + incident_type + incident_severity + fraud_reported.\n\n\nImplement k-fold cross validation for k = 10.\n\nset.seed(123)\nnum_folds &lt;- 10\nfolds &lt;- createFolds(fraud_new$total_claim_amount, k = num_folds)\n\n#fraud_new$property_damage &lt;- factor(fraud_new$property_damage, levels = c(\"Yes\", \"No\"))\n#levels_pd &lt;- levels(fraud_new$property_damage)\n\nfactor_vars &lt;- names(Filter(is.factor, fraud_new))\nfactor_levels &lt;- lapply(fraud_new[factor_vars], levels)\n\nmse_results &lt;- data.frame(\n  fold = 1:num_folds,\n  model_A_mse = NA,\n  model_B_mse = NA\n)\n\nfor (i in 1:num_folds) {\n  train_data &lt;- fraud_new[-folds[[i]], ]\n  test_data &lt;- fraud_new[folds[[i]], ]\n  \n  for (v in factor_vars) {\n    train_data[[v]] &lt;- factor(train_data[[v]], levels = factor_levels[[v]])\n    test_data[[v]]  &lt;- factor(test_data[[v]],  levels = factor_levels[[v]])\n  }\n  \n  # mod A: simple model\n  mod_A &lt;- lm(total_claim_amount ~ age + vehicles_involved + injury_claim, data = train_data)\n  pred_A &lt;- predict(mod_A, newdata = test_data)\n  mse_results$model_A_mse[i] &lt;- mean((test_data$total_claim_amount - pred_A)^2)\n  \n  # mod B: complete model\n  mod_B &lt;- lm(total_claim_amount ~ ., data = train_data)\n  pred_B &lt;- predict(mod_B, newdata = test_data)\n  mse_results$model_B_mse[i] &lt;- mean((test_data$total_claim_amount - pred_B)^2)\n}\n\n# --- In-sample residuals on full dataset ---\n# Model A\nmod_A_full &lt;- lm(total_claim_amount ~ age + vehicles_involved + injury_claim, data = fraud_new)\nresid_A &lt;- resid(mod_A_full)\n\n# Model B\nmod_B_full &lt;- lm(total_claim_amount ~ ., data = fraud_new)\nresid_B &lt;- resid(mod_B_full)\n\nsummary_table &lt;- data.frame(\n  Model = c(\"Model A\", \"Model B\"),\n  CV_MSE_Mean = c(mean(mse_results$model_A_mse), mean(mse_results$model_B_mse)),\n  CV_MSE_SD = c(sd(mse_results$model_A_mse), sd(mse_results$model_B_mse)),\n  InSample_MSE = c(\n    mean(resid(lm(total_claim_amount ~ age + vehicles_involved + injury_claim, data = fraud_new))^2),\n    mean(resid(lm(total_claim_amount ~ ., data = fraud_new))^2)\n  ),\n  InSample_SD = c(sd(resid_A^2),   sd(resid_B^2))\n)\n\nsummary_table\n\n    Model CV_MSE_Mean CV_MSE_SD InSample_MSE InSample_SD\n1 Model A   233767567  40917704    229954703   322843034\n2 Model B    69081551  11571068     65065375   107280574\n\n\n\n\nk = 639 and 5\n\n##CV using different value of k:\n##k = n=1\nset.seed(123)\nnum_folds &lt;- 639\nfolds &lt;- createFolds(fraud_new$total_claim_amount, k = num_folds)\n\n#fraud_new$property_damage &lt;- factor(fraud_new$property_damage, levels = c(\"Yes\", \"No\"))\n#levels_pd &lt;- levels(fraud_new$property_damage)\n\nfactor_vars &lt;- names(Filter(is.factor, fraud_new))\nfactor_levels &lt;- lapply(fraud_new[factor_vars], levels)\n\nmse_results &lt;- data.frame(\n  fold = 1:num_folds,\n  model_A_mse = NA,\n  model_B_mse = NA\n)\n\nfor (i in 1:num_folds) {\n  train_data &lt;- fraud_new[-folds[[i]], ]\n  test_data &lt;- fraud_new[folds[[i]], ]\n  \n  for (v in factor_vars) {\n    train_data[[v]] &lt;- factor(train_data[[v]], levels = factor_levels[[v]])\n    test_data[[v]]  &lt;- factor(test_data[[v]],  levels = factor_levels[[v]])\n  }\n  \n  # mod A: simple model\n  mod_A &lt;- lm(total_claim_amount ~ age + vehicles_involved + injury_claim, data = train_data)\n  pred_A &lt;- predict(mod_A, newdata = test_data)\n  mse_results$model_A_mse[i] &lt;- mean((test_data$total_claim_amount - pred_A)^2)\n  \n  # mod B: complete model\n  mod_B &lt;- lm(total_claim_amount ~ ., data = train_data)\n  pred_B &lt;- predict(mod_B, newdata = test_data)\n  mse_results$model_B_mse[i] &lt;- mean((test_data$total_claim_amount - pred_B)^2)\n}\n\n# --- In-sample residuals on full dataset ---\n# Model A\nmod_A_full &lt;- lm(total_claim_amount ~ age + vehicles_involved + injury_claim, data = fraud_new)\nresid_A &lt;- resid(mod_A_full)\n\n# Model B\nmod_B_full &lt;- lm(total_claim_amount ~ ., data = fraud_new)\nresid_B &lt;- resid(mod_B_full)\n\nsummary_table &lt;- data.frame(\n  Model = c(\"Model A\", \"Model B\"),\n  CV_MSE_Mean = c(mean(mse_results$model_A_mse), mean(mse_results$model_B_mse)),\n  CV_MSE_SD = c(sd(mse_results$model_A_mse), sd(mse_results$model_B_mse)),\n  InSample_MSE = c(\n    mean(resid(lm(total_claim_amount ~ age + vehicles_involved + injury_claim, data = fraud_new))^2),\n    mean(resid(lm(total_claim_amount ~ ., data = fraud_new))^2)\n  ),\n  InSample_SD = c(sd(resid_A^2),   sd(resid_B^2))\n)\n\nsummary_table\n\n    Model CV_MSE_Mean CV_MSE_SD InSample_MSE InSample_SD\n1 Model A   232967258 327286923    229954703   322843034\n2 Model B    68867218 113618315     65065375   107280574\n\n\n\n## k = 5\nset.seed(123)\nnum_folds &lt;- 5\nfolds &lt;- createFolds(fraud_new$total_claim_amount, k = num_folds)\n\n#fraud_new$property_damage &lt;- factor(fraud_new$property_damage, levels = c(\"Yes\", \"No\"))\n#levels_pd &lt;- levels(fraud_new$property_damage)\n\nfactor_vars &lt;- names(Filter(is.factor, fraud_new))\nfactor_levels &lt;- lapply(fraud_new[factor_vars], levels)\n\nmse_results &lt;- data.frame(\n  fold = 1:num_folds,\n  model_A_mse = NA,\n  model_B_mse = NA\n)\n\nfor (i in 1:num_folds) {\n  train_data &lt;- fraud_new[-folds[[i]], ]\n  test_data &lt;- fraud_new[folds[[i]], ]\n  \n  for (v in factor_vars) {\n    train_data[[v]] &lt;- factor(train_data[[v]], levels = factor_levels[[v]])\n    test_data[[v]]  &lt;- factor(test_data[[v]],  levels = factor_levels[[v]])\n  }\n  \n  # mod A: simple model\n  mod_A &lt;- lm(total_claim_amount ~ age + vehicles_involved + injury_claim, data = train_data)\n  pred_A &lt;- predict(mod_A, newdata = test_data)\n  mse_results$model_A_mse[i] &lt;- mean((test_data$total_claim_amount - pred_A)^2)\n  \n  # mod B: complete model\n  mod_B &lt;- lm(total_claim_amount ~ ., data = train_data)\n  pred_B &lt;- predict(mod_B, newdata = test_data)\n  mse_results$model_B_mse[i] &lt;- mean((test_data$total_claim_amount - pred_B)^2)\n}\n\n# --- In-sample residuals on full dataset ---\n# Model A\nmod_A_full &lt;- lm(total_claim_amount ~ age + vehicles_involved + injury_claim, data = fraud_new)\nresid_A &lt;- resid(mod_A_full)\n\n# Model B\nmod_B_full &lt;- lm(total_claim_amount ~ ., data = fraud_new)\nresid_B &lt;- resid(mod_B_full)\n\nsummary_table &lt;- data.frame(\n  Model = c(\"Model A\", \"Model B\"),\n  CV_MSE_Mean = c(mean(mse_results$model_A_mse), mean(mse_results$model_B_mse)),\n  CV_MSE_SD = c(sd(mse_results$model_A_mse), sd(mse_results$model_B_mse)),\n  InSample_MSE = c(\n    mean(resid(lm(total_claim_amount ~ age + vehicles_involved + injury_claim, data = fraud_new))^2),\n    mean(resid(lm(total_claim_amount ~ ., data = fraud_new))^2)\n  ),\n  InSample_SD = c(sd(resid_A^2),   sd(resid_B^2))\n)\n\nsummary_table\n\n    Model CV_MSE_Mean CV_MSE_SD InSample_MSE InSample_SD\n1 Model A   233223160  19807450    229954703   322843034\n2 Model B    68274384   8752033     65065375   107280574"
  }
]